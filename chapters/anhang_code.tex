\chapter{Code}

Der vollständige Quellcode dieser Arbeit steht im zugehörigen Repository zur Verfügung \cite{meinCode}.

\section{PPO-Anpassungen}
\label{sc:ppo_code}

\begin{lstlisting}[language=Python, caption={Netzarchitektur mit vollständig getrennten Pfaden}, label=lst:branching_network]
class SplitActionNet(th.nn.Module):
    def __init__(self, latent_dim: int, net_action_dims: List[int], action_space:  spaces.Dict, get_net_action_dim, net_arch: Union[list[int], dict[str, list[int]]] = [16, 16]):
        super().__init__()
        
        self.action_nets = th.nn.ModuleList()
        if isinstance(net_arch, dict):
            assert len(net_arch) == len(action_space), "If using a dict for net_arch, you must specify a separate architecture for each action in the action space"
            for key, action_dim in action_space.items():
                layers = []
                curr_dim = latent_dim
                current_net_arch = net_arch[key]
                for hidden_dim in current_net_arch:
                    layers.append(th.nn.Linear(curr_dim, hidden_dim))
                    layers.append(th.nn.Tanh())
                    curr_dim = hidden_dim
                layers.append(th.nn.Linear(curr_dim, get_net_action_dim(action_dim)))
                self.action_nets.append(th.nn.Sequential(*layers))
        else:
            shared_net = []
            curr_dim = latent_dim
            for hidden_dim in net_arch:
                shared_net.append(th.nn.Linear(curr_dim, hidden_dim))
                shared_net.append(th.nn.Tanh())
                curr_dim = hidden_dim
            
            self.action_nets = th.nn.ModuleList()
                
            for action_dim in action_space.values():
                action_net = th.nn.Sequential(*shared_net).append(th.nn.Linear(curr_dim, get_net_action_dim(action_dim)))
                self.action_nets.append(action_net)


    def forward(self, x: th.Tensor) -> th.Tensor:
        return th.cat([action_net(x) for action_net in self.action_nets], dim=1)
    
class Masked_MultiOutputDistribution(MultiOutputDistribution):
    
    def proba_distribution_net(self, latent_dim: int, log_std_init: float = 0.0) -> Tuple[th.nn.Module, th.nn.Parameter]:
        action_net = SplitActionNet(latent_dim, self._net_action_dims, self.action_space, self.get_net_action_dim)
        flatten_log_std = th.nn.Parameter(th.ones(self._net_flatten_action_dim) * log_std_init, requires_grad=True)
        return action_net, flatten_log_std
\end{lstlisting}

\begin{lstlisting}[language=Python, caption={Maskierung in der Aktionsauswertung}, label=lst:evaluate_actions]
def evaluate_actions(self, obs: th.Tensor, actions: th.Tensor) -> Tuple[th.Tensor, th.Tensor, th.Tensor]:
        features = self.extract_features(obs)
        if self.share_features_extractor:
            latent_pi, latent_vf = self.mlp_extractor(features)
        else:
            pi_features, vf_features = features
            latent_pi = self.mlp_extractor.forward_actor(pi_features)
            latent_vf = self.mlp_extractor.forward_critic(vf_features)
            
        distribution = self._get_action_dist_from_latent(latent_pi)
        values = self.value_net(latent_vf)
        assert(isinstance(distribution, Masked_MultiOutputDistribution))

        
        split_actions = th.split(actions, distribution.action_dims, dim=1)
        act_type = split_actions[0].squeeze(-1)
        
        stack_log_prob = distribution.stack_log_prob(actions)
        lp_type = stack_log_prob[:, 0]
        lp_steer = stack_log_prob[:, 1]
        
        mask_steer = (act_type.round().long() == STEER_INDEX)
        masked_lp_steer = th.where(mask_steer, lp_steer, th.zeros_like(lp_steer))
        masked_log_prob = lp_type + masked_lp_steer
        
        
        stack_entropy = distribution.stack_entropy()
        ent_type = stack_entropy[:, 0]
        ent_steer = stack_entropy[:, 1]
        
        with th.no_grad():
            type_probs = distribution.distribution[0].distribution.probs
            p_steer = type_probs[:, STEER_INDEX]
        masked_ent_steer = p_steer * ent_steer
        masked_entropy = ent_type + masked_ent_steer
    
        return values, masked_log_prob, masked_entropy
\end{lstlisting}

\begin{lstlisting}[language=Python, caption={Maskierung im Forwardschritt}, label=lst:forward]
 def forward(self, obs: th.Tensor, deterministic: bool = False) -> Tuple[th.Tensor, th.Tensor, th.Tensor]:
        features = self.extract_features(obs)
        if self.share_features_extractor:
            latent_pi, latent_vf = self.mlp_extractor(features)
        else:
            pi_features, vf_features = features
            latent_pi = self.mlp_extractor.forward_actor(pi_features)
            latent_vf = self.mlp_extractor.forward_critic(vf_features)
            
        values = self.value_net(latent_vf)
        distribution = self._get_action_dist_from_latent(latent_pi)
        actions = distribution.get_actions(deterministic=deterministic)
        assert(isinstance(distribution, Masked_MultiOutputDistribution))
        
        split_actions = th.split(actions, distribution.action_dims, dim=1)
        act_type = split_actions[0].squeeze(-1)
        
        stack_log_prob = distribution.stack_log_prob(actions)
        lp_type = stack_log_prob[:, 0]
        lp_steer = stack_log_prob[:, 1]
        
        mask_steer = (act_type.round().long() == STEER_INDEX)
        masked_lp_steer = th.where(mask_steer, lp_steer, th.zeros_like(lp_steer))
        masked_log_prob = lp_type + masked_lp_steer
        
        actions = actions.reshape((-1, *get_action_shape(self.action_space)))
        
        return actions, values, masked_log_prob
\end{lstlisting}


